{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b1dca-566e-4f61-aee7-e70677562a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "# 下载 NLTK 资源\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# 读取数据集\n",
    "df = pd.read_csv('Query_Classification_Dataset.csv')\n",
    "\n",
    "# 初始化停用词和标点符号\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# 初始化词干提取器\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# 文本预处理函数\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# 对数据集中的查询进行预处理\n",
    "df['Processed_Query'] = df['Query'].apply(preprocess_text)\n",
    "\n",
    "# 创建 TF-IDF 向量化器\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Processed_Query'])\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# 划分数据集\n",
    "X = tfidf_matrix\n",
    "y = df['Category']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 定义模型训练和评估函数\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_accuracy, lr_f1 = train_and_evaluate_model(lr_model, X_train, X_test, y_train, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "print(\"Logistic Regression F1-score:\", lr_f1)\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_accuracy, svm_f1 = train_and_evaluate_model(svm_model, X_train, X_test, y_train, y_test)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"SVM F1-score:\", svm_f1)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_accuracy, rf_f1 = train_and_evaluate_model(rf_model, X_train, X_test, y_train, y_test)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Random Forest F1-score:\", rf_f1)\n",
    "\n",
    "# Gradient Boosting\n",
    "gbm_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gbm_accuracy, gbm_f1 = train_and_evaluate_model(gbm_model, X_train, X_test, y_train, y_test)\n",
    "print(\"Gradient Boosting Accuracy:\", gbm_accuracy)\n",
    "print(\"Gradient Boosting F1-score:\", gbm_f1)\n",
    "\n",
    "# AdaBoost\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "adaboost_accuracy, adaboost_f1 = train_and_evaluate_model(adaboost_model, X_train, X_test, y_train, y_test)\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
    "print(\"AdaBoost F1-score:\", adaboost_f1)\n",
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_accuracy, knn_f1 = train_and_evaluate_model(knn_model, X_train, X_test, y_train, y_test)\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n",
    "print(\"KNN F1-score:\", knn_f1)\n",
    "\n",
    "# BERT 模型部分\n",
    "def bert_classification():\n",
    "    # 使用 BERT 的预训练 tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # 将文本编码为 BERT 所需的格式\n",
    "    def encode_text(text):\n",
    "        return tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=64,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    # 创建自定义 Dataset 类\n",
    "    class TextDataset(Dataset):\n",
    "        def __init__(self, texts, labels):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            text = self.texts[idx]\n",
    "            label = self.labels[idx]\n",
    "            encoding = encode_text(text)\n",
    "            return {'input_ids': encoding['input_ids'].squeeze(),\n",
    "                    'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                    'labels': torch.tensor(label, dtype=torch.long)}\n",
    "\n",
    "    # 准备数据集\n",
    "    X = df['Query'].values\n",
    "    y = df['Category'].factorize()[0]  # 类别标签\n",
    "\n",
    "    # 划分数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建训练和测试集\n",
    "    train_dataset = TextDataset(X_train, y_train)\n",
    "    test_dataset = TextDataset(X_test, y_test)\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "    # 加载预训练 BERT 模型\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['Category'].unique()))\n",
    "\n",
    "    # 设置优化器\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # 训练模型\n",
    "    model.train()\n",
    "    for epoch in range(3):  # 训练 3 个 epoch\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 获取输入和标签\n",
    "            input_ids = batch['input_ids'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            attention_mask = batch['attention_mask'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            labels = batch['labels'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            attention_mask = batch['attention_mask'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            labels = batch['labels'].to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, predicted = torch.max(logits, dim=1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 评估模型\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"BERT Accuracy: {accuracy}\")\n",
    "    print(f\"BERT F1-score: {f1}\")\n",
    "\n",
    "# 运行 BERT 分类\n",
    "bert_classification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
